"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[1093],{2703:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"capstone-project","title":"Capstone Project: The Autonomous Humanoid","description":"Project Overview and Requirements","source":"@site/docs/capstone-project.md","sourceDirName":".","slug":"/capstone-project","permalink":"/physical-ai-humanoid-robotics/docs/capstone-project","draft":false,"unlisted":false,"editUrl":"https://github.com/subhanghani339/physical-ai-humanoid-robotics/edit/main/docs/capstone-project.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Conversational Robotics (Week 13)","permalink":"/physical-ai-humanoid-robotics/docs/module-4-humanoid/conversational-robotics"}}');var t=i(4848),s=i(8453);const r={sidebar_position:1},a="Capstone Project: The Autonomous Humanoid",l={},c=[{value:"Project Overview and Requirements",id:"project-overview-and-requirements",level:2},{value:"Step-by-Step Implementation Guide",id:"step-by-step-implementation-guide",level:2},{value:"Phase 1: Voice Command &amp; NLP Integration (Weeks 1-2)",id:"phase-1-voice-command--nlp-integration-weeks-1-2",level:3},{value:"Phase 2: Perception and Navigation (Weeks 3-5)",id:"phase-2-perception-and-navigation-weeks-3-5",level:3},{value:"Phase 3: Object Manipulation (Weeks 6-8)",id:"phase-3-object-manipulation-weeks-6-8",level:3},{value:"Phase 4: Integration and Refinement (Weeks 9-10)",id:"phase-4-integration-and-refinement-weeks-9-10",level:3},{value:"Assessment Criteria",id:"assessment-criteria",level:2},{value:"Submission Guidelines",id:"submission-guidelines",level:2}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"capstone-project-the-autonomous-humanoid",children:"Capstone Project: The Autonomous Humanoid"})}),"\n",(0,t.jsx)(n.h2,{id:"project-overview-and-requirements",children:"Project Overview and Requirements"}),"\n",(0,t.jsx)(n.p,{children:'The capstone project for "Physical AI & Humanoid Robotics" challenges you to integrate the knowledge and skills acquired throughout the course to develop a foundational system for an autonomous humanoid robot. Your goal is to create a modular and extensible framework that enables the robot to understand and execute high-level voice commands to interact with its physical environment.'}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Core Requirements"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Voice Command Interface"}),": The robot must be able to receive and interpret natural language voice commands."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Task Planning"}),": Translate high-level commands into a sequence of actionable robotic tasks."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Navigation"}),": Enable the robot to move autonomously within a simulated environment to reach specified locations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Object Manipulation"}),": Allow the robot to identify, approach, and manipulate (pick and place) designated objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Modular Design"}),": The system should be built with modular components (ROS 2 nodes, Isaac GEMs, etc.) to facilitate future expansion."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"step-by-step-implementation-guide",children:"Step-by-Step Implementation Guide"}),"\n",(0,t.jsx)(n.p,{children:"This guide provides a suggested pathway for implementing your capstone project. You are encouraged to innovate and adapt these steps as needed."}),"\n",(0,t.jsx)(n.h3,{id:"phase-1-voice-command--nlp-integration-weeks-1-2",children:"Phase 1: Voice Command & NLP Integration (Weeks 1-2)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Set up Speech-to-Text"}),": Integrate OpenAI Whisper (or a similar ASR system) to convert spoken commands into text."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Natural Language Understanding (NLU)"}),': Develop a component (e.g., using a small LLM, rule-based system, or NLU library) to extract intent (e.g., "navigate", "pick", "report") and entities (e.g., "kitchen", "red block", "status") from text commands.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Basic Command Mapping"}),': Map simple intents to predefined robot actions (e.g., "Go to the door" -> navigate to door coordinates).']}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-2-perception-and-navigation-weeks-3-5",children:"Phase 2: Perception and Navigation (Weeks 3-5)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Environment Setup"}),": Create a simple indoor environment in Isaac Sim or Gazebo with a few distinct locations and objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Integration"}),": Configure simulated sensors (RGB-D camera, LIDAR, IMU) and process their data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Localization and Mapping (SLAM)"}),": Implement or integrate a ROS 2 package for robot localization within the simulated environment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Path Planning"}),": Develop a navigation stack (e.g., using Nav2 in ROS 2) to plan collision-free paths to target locations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Autonomous Movement"}),": Implement control loops to execute planned paths and move the humanoid robot to specified goals."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-3-object-manipulation-weeks-6-8",children:"Phase 3: Object Manipulation (Weeks 6-8)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Object Detection"}),': Train or integrate an AI model to detect and identify objects (e.g., "red block", "blue cup") in the robot\'s visual field.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Grasping Point Detection"}),": Develop a method to determine suitable grasping points on detected objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Inverse Kinematics (IK)"}),": Utilize IK solvers to calculate the joint angles required for the robot's arm to reach and grasp objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Manipulation Planning"}),": Plan a sequence of arm movements for picking up an object, avoiding collisions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Execution"}),": Implement control for the robot's gripper and arm to perform pick-and-place operations."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"phase-4-integration-and-refinement-weeks-9-10",children:"Phase 4: Integration and Refinement (Weeks 9-10)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"End-to-End Integration"}),': Combine all modules (voice, NLU, navigation, manipulation) to execute complex multi-step commands (e.g., "Go to the table, pick up the red block, and bring it to me.").']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Error Handling"}),": Implement basic error detection and recovery mechanisms (e.g., if navigation fails, try an alternative path; if grasp fails, retry)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human Feedback"}),": Allow for corrective voice commands or interruptions during task execution."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Performance Optimization"}),": Refine algorithms for real-time performance in simulation."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"assessment-criteria",children:"Assessment Criteria"}),"\n",(0,t.jsx)(n.p,{children:"Your project will be assessed based on the following criteria:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Functionality"}),": How well does the robot respond to and execute various voice commands?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Robustness"}),": How reliably does the system perform in different scenarios and handle unexpected events?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Modularity"}),": The clarity, organization, and extensibility of your codebase."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Documentation"}),": Clear explanations of your design choices, implementation details, and how to run your system."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Innovation"}),": Any unique features, approaches, or improvements beyond the core requirements."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Presentation"}),": A demonstration of your robot's capabilities and an explanation of your work."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"submission-guidelines",children:"Submission Guidelines"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Code Repository"}),": A well-structured GitHub repository containing all your source code."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Project Report"}),": A detailed report outlining your design, implementation, challenges, and results."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Demo Video"}),": A video demonstrating your robot successfully executing a range of commands in the simulated environment."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var o=i(6540);const t={},s=o.createContext(t);function r(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);